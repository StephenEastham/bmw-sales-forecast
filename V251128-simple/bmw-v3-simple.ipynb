{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMW Sales Analysis\n",
    "\n",
    "\n",
    "1. Data Loading & Preprocessing\n",
    "2. Exploratory Data Analysis\n",
    "3. Time Series Aggregation\n",
    "4. Visualization (Static & Interactive)\n",
    "5. Reporting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports and note: modules are embedded in subsequent cells\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- config.py (embedded) ---\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "PROJECT_ROOT = Path().resolve()\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'outputs'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def out_path(name: str) -> str:\n",
    "    return str(OUTPUT_DIR / name)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "matplotlib.use('Agg')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "DATA_CSV_URL = 'https://raw.githubusercontent.com/StephenEastham/bmw-sales-forecast/refs/heads/main/v251125/BMW-sales-data-2010-2024.csv'\n",
    "DATA_CSV_FILE = 'BMW-sales-data-2010-2024.csv'\n",
    "\n",
    "\n",
    "# Feature Flags\n",
    "ENABLE_DATA_PROCESSING = True\n",
    "ENABLE_EXPLORATORY_ANALYSIS = True\n",
    "ENABLE_TIME_SERIES = True\n",
    "ENABLE_STATIC_PLOTS = True\n",
    "ENABLE_REPORTING = True\n",
    "ENABLE_DASHBOARDS = True\n",
    "ENABLE_AGGREGATOR = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- utils.py (embedded) ---\n",
    "import logging\n",
    "import shutil\n",
    "import os\n",
    "from zipfile import ZipFile, ZIP_DEFLATED\n",
    "\n",
    "def clean_outputs():\n",
    "    \"\"\"Delete all files in the output directory.\"\"\"\n",
    "    print(f\"Cleaning output directory: {OUTPUT_DIR}\")\n",
    "    if OUTPUT_DIR.exists():\n",
    "        for item in OUTPUT_DIR.iterdir():\n",
    "            try:\n",
    "                if item.is_file():\n",
    "                    item.unlink()\n",
    "                elif item.is_dir():\n",
    "                    shutil.rmtree(item)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {item}: {e}\")\n",
    "    else:\n",
    "        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def setup_logger(log_file='sales_alerts.log'):\n",
    "    \"\"\"Setup logging to file and console\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(out_path(log_file)),\n",
    "            logging.StreamHandler()\n",
    "        ],\n",
    "        force=True\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "def print_section(title):\n",
    "    \"\"\"Print a formatted section header\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(title)\n",
    "    print(\"=\"*80)\n",
    "\n",
    "def zip_all_outputs(zip_filename=None, patterns=('*.png','*.html','*.csv','*.txt')):\n",
    "    \"\"\"Create a zip archive of generated outputs in `OUTPUT_DIR`.\"\"\"\n",
    "    if zip_filename is None:\n",
    "        zip_path = OUTPUT_DIR / 'all_outputs.zip'\n",
    "    else:\n",
    "        zip_path = Path(zip_filename)\n",
    "        if not zip_path.is_absolute():\n",
    "            zip_path = OUTPUT_DIR / zip_path\n",
    "\n",
    "    # Ensure OUTPUT_DIR exists\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    added = 0\n",
    "    try:\n",
    "        with ZipFile(zip_path, 'w', ZIP_DEFLATED) as zf:\n",
    "            for pat in patterns:\n",
    "                for p in OUTPUT_DIR.glob(pat):\n",
    "                    if p.is_file():\n",
    "                        zf.write(p, arcname=p.name)\n",
    "                        added += 1\n",
    "        print(f\"‚úÖ Created zip: {zip_path.resolve()} ({added} files)\")\n",
    "        return zip_path\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error while creating zip: {e}\")\n",
    "        raise\n",
    "# --- end utils ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- data.py (embedded) ---\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "# uses DATA_CSV_FILE, DATA_CSV_URL, HOWTO_FILE, HOWTO_URL from config\n",
    "\n",
    "def download_data_file(file_name, data_url):\n",
    "    if not os.path.exists(file_name):\n",
    "        try:\n",
    "            print(f\"Attempting to download {file_name} from {data_url}...\")\n",
    "            response = requests.get(data_url)\n",
    "            response.raise_for_status()\n",
    "            with open(file_name, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"‚úÖ {file_name} downloaded successfully!\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå Failed to download {file_name}. Please ensure the URL is correct and accessible.\\nError: {e}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ {file_name} already exists.\")\n",
    "\n",
    "def download_required_files():\n",
    "    download_data_file(DATA_CSV_FILE, DATA_CSV_URL)\n",
    "\n",
    "def load_and_explore_data(csv_path):\n",
    "    print_section(\"üìä DATASET OVERVIEW\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"\\n‚úÖ Data loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head(10))\n",
    "    print(f\"\\nColumn names and types:\")\n",
    "    print(df.dtypes)\n",
    "    print(f\"\\nData summary:\")\n",
    "    print(df.describe())\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df_clean = df.copy()\n",
    "    print_section(\"üìã COLUMN ANALYSIS\")\n",
    "    print('\\nColumn names:')\n",
    "    for i, col in enumerate(df_clean.columns, 1):\n",
    "        print(f\"  {i}. '{col}' ({df_clean[col].dtype})\")\n",
    "    print(f\"\\nüîç Missing values:\")\n",
    "    print(df_clean.isnull().sum())\n",
    "    df_clean.columns = df_clean.columns.str.strip()\n",
    "    empty_columns = []\n",
    "    for col in df_clean.columns:\n",
    "        non_na = ~df_clean[col].isna()\n",
    "        if non_na.any():\n",
    "            non_empty = df_clean.loc[non_na, col].astype(str).str.strip() != ''\n",
    "            has_values = non_empty.any()\n",
    "        else:\n",
    "            has_values = False\n",
    "        if not has_values:\n",
    "            empty_columns.append(col)\n",
    "    if empty_columns:\n",
    "        print(\"\\n‚ö†Ô∏è Warning: The following columns contain empty values:\")\n",
    "        for c in empty_columns:\n",
    "            print(f\"  - {c}\")\n",
    "        print(\"Consider dropping or filling these columns before further processing.\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No empty columns found. All columns contain at least one non-empty value.\")\n",
    "    print(f\"\\n‚úÖ Data preprocessing complete. Shape: {df_clean.shape}\")\n",
    "    print(f\"\\nüìä Cleaned columns:\")\n",
    "    print(df_clean.columns.tolist())\n",
    "    return df_clean\n",
    "# --- end data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- analysis.py (embedded) ---\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_time_series(df_clean):\n",
    "    print_section(\"üìà TIME SERIES AGGREGATION\")\n",
    "    df_yearly = df_clean.groupby('Year')['Sales_Volume'].sum().reset_index()\n",
    "    df_yearly = df_yearly.sort_values('Year')\n",
    "    df_yearly.columns = ['Year', 'Total_Sales']\n",
    "    print(f\"\\n‚úÖ Yearly Sales Aggregation:\")\n",
    "    print(df_yearly)\n",
    "    ts_data = df_yearly['Total_Sales'].values\n",
    "    ts_years = df_yearly['Year'].values\n",
    "    print(f\"\\nüìä Time Series Summary:\")\n",
    "    print(f\"   Total years: {len(ts_years)}\")\n",
    "    print(f\"   Date range: {ts_years[0]:.0f} - {ts_years[-1]:.0f}\")\n",
    "    print(f\"   Average annual sales: {ts_data.mean():,.0f}\")\n",
    "    print(f\"   Peak sales: {ts_data.max():,.0f} (Year {ts_years[np.argmax(ts_data)]:.0f})\")\n",
    "    print(f\"   Lowest sales: {ts_data.min():,.0f} (Year {ts_years[np.argmin(ts_data)]:.0f})\")\n",
    "    df_yearly['YoY_Growth'] = df_yearly['Total_Sales'].pct_change() * 100\n",
    "    print(f\"\\nüìä Year-over-Year Growth:\")\n",
    "    print(df_yearly[['Year', 'Total_Sales', 'YoY_Growth']].to_string(index=False))\n",
    "    df_model_yearly = df_clean.groupby(['Year', 'Model'])['Sales_Volume'].sum().reset_index()\n",
    "    df_region_yearly = df_clean.groupby(['Year', 'Region'])['Sales_Volume'].sum().reset_index()\n",
    "    print(f\"\\n‚úÖ Model and Region time series aggregations complete\")\n",
    "    return df_yearly, ts_data, ts_years, df_model_yearly, df_region_yearly\n",
    "# --- end analysis ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- exploratory_analysis.py (embedded) ---\n",
    "def exploratory_data_analysis(df_clean):\n",
    "    print_section(\"üìä EXPLORATORY DATA ANALYSIS\")\n",
    "    print(\"\\nüèéÔ∏è Sales by Model (Top 10):\")\n",
    "    model_sales = df_clean.groupby('Model')['Sales_Volume'].sum().sort_values(ascending=False)\n",
    "    print(model_sales.head(10))\n",
    "    print(\"\\nüåç Sales by Region:\")\n",
    "    region_sales = df_clean.groupby('Region')['Sales_Volume'].sum().sort_values(ascending=False)\n",
    "    print(region_sales)\n",
    "    print(\"\\nüìÖ Sales by Year:\")\n",
    "    year_sales = df_clean.groupby('Year')['Sales_Volume'].sum().sort_values()\n",
    "    print(year_sales)\n",
    "    print(\"\\nüìà Sales Volume Statistics:\")\n",
    "    print(df_clean['Sales_Volume'].describe())\n",
    "    print(\"\\nüí∞ Price Statistics:\")\n",
    "    print(df_clean['Price_USD'].describe())\n",
    "# --- end exploratory_analysis ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- viz_static.py (embedded) ---\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def create_overview_visualizations(df_yearly, df_clean):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle('BMW Sales Overview (2010-2024)', fontsize=16, fontweight='bold')\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(df_yearly['Year'], df_yearly['Total_Sales'], marker='o', linewidth=2.5, \n",
    "             markersize=8, color='#1f77b4', label='Total Sales')\n",
    "    ax1.set_xlabel('Year', fontsize=11, fontweight='bold')\n",
    "    ax1.set_ylabel('Sales', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Total Sales Trend', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    ax2 = axes[0, 1]\n",
    "    colors = ['green' if x > 0 else 'red' for x in df_yearly['YoY_Growth'].fillna(0)]\n",
    "    ax2.bar(df_yearly['Year'][1:], df_yearly['YoY_Growth'][1:], color=colors[1:], alpha=0.7)\n",
    "    ax2.set_xlabel('Year', fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel('Growth Rate (%)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Year-over-Year Growth Rate', fontsize=12, fontweight='bold')\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    ax3 = axes[1, 0]\n",
    "    model_total = df_clean.groupby('Model')['Sales_Volume'].sum().sort_values(ascending=True).tail(10)\n",
    "    model_total.plot(kind='barh', ax=ax3, color='#ff7f0e', alpha=0.8)\n",
    "    ax3.set_xlabel('Total Sales', fontsize=11, fontweight='bold')\n",
    "    ax3.set_title('Top 10 Models by Sales', fontsize=12, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3, axis='x')\n",
    "    ax4 = axes[1, 1]\n",
    "    region_total = df_clean.groupby('Region')['Sales_Volume'].sum().sort_values(ascending=False)\n",
    "    colors_region = plt.cm.Set3(np.linspace(0, 1, len(region_total)))\n",
    "    ax4.pie(region_total, labels=region_total.index, autopct='%1.1f%%', \n",
    "            colors=colors_region, startangle=90)\n",
    "    ax4.set_title('Sales Distribution by Region', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    p = out_path('01_sales_overview.png')\n",
    "    plt.savefig(p, dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úÖ Saved: {p}\")\n",
    "    plt.close()\n",
    "\n",
    "def create_heatmap(df_clean):\n",
    "    heatmap_data = df_clean.pivot_table(\n",
    "        values='Sales_Volume',\n",
    "        index='Model',\n",
    "        columns='Region',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "    heatmap_data = heatmap_data.loc[heatmap_data.sum(axis=1).nlargest(15).index]\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='YlOrRd', cbar_kws={'label': 'Sales'})\n",
    "    plt.title('Sales Heatmap: Model vs Region (Top 15 Models)', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Region', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Model', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    p = out_path('02_model_region_heatmap.png')\n",
    "    plt.savefig(p, dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úÖ Saved: {p}\")\n",
    "    plt.close()\n",
    "# --- end viz_static ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- viz_interactive.py (embedded) ---\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def create_interactive_dashboard(ts_years, ts_data, df_yearly, df_clean):\n",
    "    print_section(\"üìä CREATING INTERACTIVE DASHBOARD\")\n",
    "    fig_forecast = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Total Sales Trend',\n",
    "            'Year-over-Year Growth',\n",
    "            'Model Performance (Top 5)',\n",
    "            'Regional Distribution'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'scatter'}, {'type': 'bar'}],\n",
    "            [{'type': 'bar'}, {'type': 'pie'}]\n",
    "        ]\n",
    "    )\n",
    "    fig_forecast.add_trace(\n",
    "        go.Scatter(\n",
    "            x=ts_years, y=ts_data, mode='lines+markers',\n",
    "            name='Historical Sales', line=dict(color='#1f77b4', width=2),\n",
    "            marker=dict(size=8)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig_forecast.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_yearly['Year'][1:], y=df_yearly['YoY_Growth'][1:],\n",
    "            name='Growth Rate', marker=dict(\n",
    "                color=df_yearly['YoY_Growth'][1:],\n",
    "                colorscale='RdYlGn', showscale=False\n",
    "            )\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    top_5_models = df_clean.groupby('Model')['Sales_Volume'].sum().nlargest(5).sort_values()\n",
    "    fig_forecast.add_trace(\n",
    "        go.Bar(\n",
    "            y=top_5_models.index, x=top_5_models.values,\n",
    "            orientation='h', name='Model Sales', \n",
    "            marker=dict(color='#ff7f0e')\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    region_dist = df_clean.groupby('Region')['Sales_Volume'].sum()\n",
    "    fig_forecast.add_trace(\n",
    "        go.Pie(\n",
    "            labels=region_dist.index, values=region_dist.values,\n",
    "            name='Regions'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    fig_forecast.update_xaxes(title_text=\"Year\", row=1, col=1)\n",
    "    fig_forecast.update_yaxes(title_text=\"Sales\", row=1, col=1)\n",
    "    fig_forecast.update_xaxes(title_text=\"Year\", row=1, col=2)\n",
    "    fig_forecast.update_yaxes(title_text=\"Growth %\", row=1, col=2)\n",
    "    fig_forecast.update_xaxes(title_text=\"Sales\", row=2, col=1)\n",
    "    fig_forecast.update_yaxes(title_text=\"Model\", row=2, col=1)\n",
    "    fig_forecast.update_layout(\n",
    "        title_text=\"BMW Sales Analytics Dashboard\",\n",
    "        showlegend=True,\n",
    "        height=900,\n",
    "        width=1400\n",
    "    )\n",
    "    p = out_path('05_interactive_dashboard.html')\n",
    "    fig_forecast.write_html(p)\n",
    "    print(f\"\\n‚úÖ Saved: {p}\")\n",
    "\n",
    "def create_heatmap_interactive(df_model_yearly):\n",
    "    heatmap_data_pivot = df_model_yearly.pivot_table(\n",
    "        values='Sales_Volume',\n",
    "        index='Model',\n",
    "        columns='Year',\n",
    "        fill_value=0\n",
    "    )\n",
    "    heatmap_data_pivot = heatmap_data_pivot.loc[heatmap_data_pivot.sum(axis=1).nlargest(10).index]\n",
    "    fig_heatmap = go.Figure(data=go.Heatmap(\n",
    "        z=heatmap_data_pivot.values,\n",
    "        x=heatmap_data_pivot.columns,\n",
    "        y=heatmap_data_pivot.index,\n",
    "        colorscale='YlOrRd',\n",
    "        colorbar=dict(title='Sales')\n",
    "    ))\n",
    "    fig_heatmap.update_layout(\n",
    "        title='BMW Model Sales Trends Over Years (Top 10 Models)',\n",
    "        xaxis_title='Year',\n",
    "        yaxis_title='Model',\n",
    "        height=600,\n",
    "        width=1200\n",
    "    )\n",
    "    p = out_path('06_model_heatmap_interactive.html')\n",
    "    fig_heatmap.write_html(p)\n",
    "    print(f\"‚úÖ Saved: {p}\")\n",
    "# --- end viz_interactive ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- reporting.py (embedded) ---\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_monthly_report(df_clean, average_sales):\n",
    "    timestamp = datetime.now()\n",
    "    report = ('='*80) + '\\n' + 'BMW SALES ANALYTICS - MONTHLY REPORT' + '\\n' + f'Generated: {timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")}' + '\\n' + ('='*80) + '\\n\\n'\n",
    "    report += '1. EXECUTIVE SUMMARY\\n' + ('-'*80) + '\\n'\n",
    "    report += f'   ‚Ä¢ Report Period: {timestamp.strftime(\"%B %Y\")}\\n'\n",
    "    report += '   ‚Ä¢ Number of Active Alerts: 0 (alerting disabled)\\n\\n'\n",
    "    report += '2. KEY METRICS\\n' + ('-'*80) + '\\n'\n",
    "    report += f'   ‚Ä¢ Historical Average Sales: {average_sales:,.0f}\\n'\n",
    "    report += '   ‚Ä¢ Year-over-Year Change: N/A\\n\\n'\n",
    "    report += '3. ALERTS & ACTION ITEMS\\n' + ('-'*80) + '\\n'\n",
    "    report += '   No alerts configured for this simplified run.\\n\\n'\n",
    "    report += '\\n5. MODEL PERFORMANCE (Top 5)\\n' + ('-'*80) + '\\n'\n",
    "    top_performers = df_clean.groupby('Model')['Sales_Volume'].sum().nlargest(5)\n",
    "    for i, (model, sales) in enumerate(top_performers.items(), 1):\n",
    "        report += f'   {i}. {model}: {sales:,.0f}\\n'\n",
    "    report += '\\n6. REGIONAL PERFORMANCE\\n' + ('-'*80) + '\\n'\n",
    "    by_region = df_clean.groupby('Region')['Sales_Volume'].sum().sort_values(ascending=False)\n",
    "    for region, sales in by_region.items():\n",
    "        pct = (sales / by_region.sum() * 100)\n",
    "        report += f'   ‚Ä¢ {region}: {sales:,.0f} ({pct:.1f}%)\\n'\n",
    "    report += '\\n7. RECOMMENDATIONS\\n' + ('-'*80) + '\\n'\n",
    "    report += '   ‚Ä¢ Monitor underperforming models closely\\n'\n",
    "    report += '   ‚Ä¢ Invest in high-growth regions\\n'\n",
    "    report += '   ‚Ä¢ Adjust inventory based on demand signals\\n'\n",
    "    report += '   ‚Ä¢ Review market conditions quarterly\\n\\n'\n",
    "    report += ('='*80) + '\\nEND OF REPORT\\n' + ('='*80) + '\\n'\n",
    "    return report\n",
    "\n",
    "def generate_final_summary(df_clean, average_sales, ts_years, ts_data):\n",
    "     import numpy as np\n",
    "     total_records = len(df_clean) if df_clean is not None else 0\n",
    "     year_min = int(df_clean['Year'].min()) if (df_clean is not None and 'Year' in df_clean.columns) else 'N/A'\n",
    "     year_max = int(df_clean['Year'].max()) if (df_clean is not None and 'Year' in df_clean.columns) else 'N/A'\n",
    "     top_model = df_clean.groupby('Model')['Sales_Volume'].sum().idxmax() if (df_clean is not None and 'Model' in df_clean.columns) else 'N/A'\n",
    "     top_region = df_clean.groupby('Region')['Sales_Volume'].sum().idxmax() if (df_clean is not None and 'Region' in df_clean.columns) else 'N/A'\n",
    "     avg_sales = average_sales\n",
    "     peak_year = 'N/A'\n",
    "     peak_value = 'N/A'\n",
    "     low_year = 'N/A'\n",
    "     low_value = 'N/A'\n",
    "     trend = 'N/A'\n",
    "     try:\n",
    "          if ts_years is not None and ts_data is not None and len(ts_years) > 0 and len(ts_data) > 0:\n",
    "                peak_idx = int(np.argmax(ts_data))\n",
    "                peak_year = int(ts_years[peak_idx])\n",
    "                peak_value = int(ts_data.max())\n",
    "                low_idx = int(np.argmin(ts_data))\n",
    "                low_year = int(ts_years[low_idx])\n",
    "                low_value = int(ts_data.min())\n",
    "                trend = 'GROWING' if ts_data[-1] > ts_data[0] else 'DECLINING'\n",
    "     except Exception:\n",
    "          pass\n",
    "     summary = ('='*80) + '\\n' + 'BMW SALES ANALYTICS - ANALYSIS COMPLETE' + '\\n' + ('='*80) + '\\n\\n'\n",
    "     summary += f'ANALYSIS COMPLETED:\\n\\n1. Data Overview:\\n    ‚Ä¢ Total records analyzed: {total_records:,}\\n    ‚Ä¢ Time period: {year_min} - {year_max}\\n    ‚Ä¢ Models tracked: {df_clean[\"Model\"].nunique() if df_clean is not None else 0}\\n    ‚Ä¢ Regions tracked: {df_clean[\"Region\"].nunique() if df_clean is not None else 0}\\n\\n'\n",
    "     summary += f'2. Historical Performance:\\n    ‚Ä¢ Average annual sales: {avg_sales:,.0f}\\n    ‚Ä¢ Peak sales year: {peak_year} ({peak_value:,})\\n    ‚Ä¢ Lowest sales year: {low_year} ({low_value:,})\\n    ‚Ä¢ Trend: {trend}\\n\\n'\n",
    "     summary += '3. Visualizations Generated:\\n    [OK] 01_sales_overview.png - Overview charts (4-panel analysis)\\n    [OK] 02_model_region_heatmap.png - Performance matrix\\n    [OK] 05_interactive_dashboard.html - Main interactive dashboard\\n    [OK] 06_model_heatmap_interactive.html - Interactive heatmap\\n    [OK] 07_all_outputs.html - Aggregated outputs page\\n\\n'\n",
    "     summary += '4. Data Files Generated:\\n    [OK] sales_report_[timestamp].txt - Detailed report\\n    [OK] ANALYSIS_SUMMARY.txt - This summary\\n\\n'\n",
    "     summary += f'5. Top Insights:\\n    ‚Ä¢ Top Model: {top_model}\\n    ‚Ä¢ Top Region: {top_region}\\n\\n'\n",
    "     summary += ('='*80) + '\\nPROJECT STATUS: ANALYSIS COMPLETE (Forecasting & Alerts Removed)\\n' + ('='*80) + '\\n'\n",
    "     print(summary)\n",
    "     with open(out_path('ANALYSIS_SUMMARY.txt'), 'w', encoding='utf-8') as f:\n",
    "          f.write(summary)\n",
    "     print(f\"\\n[OK] Saved: {out_path('ANALYSIS_SUMMARY.txt')}\")\n",
    "# --- end reporting ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- aggregator.py (embedded) ---\n",
    "import os\n",
    "import webbrowser\n",
    "from pathlib import Path\n",
    "\n",
    "def create_aggregator_html():\n",
    "    out_html = '07_all_outputs.html'\n",
    "    pngs = sorted([str(p) for p in OUTPUT_DIR.glob('*.png')])\n",
    "    exclude_names = {out_html, 'commit_messages-can-change-values.html'}\n",
    "    htmls = sorted([str(p) for p in OUTPUT_DIR.glob('*.html') if os.path.basename(p) not in exclude_names])\n",
    "    if not pngs and not htmls:\n",
    "        print('No output PNG or HTML files found in the current directory.')\n",
    "    else:\n",
    "        parts = []\n",
    "        parts.append('<!doctype html>')\n",
    "        parts.append('<html lang=\"en\">')\n",
    "        parts.append('<head>')\n",
    "        parts.append('<meta charset=\"utf-8\"/>')\n",
    "        parts.append('<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/>')\n",
    "        parts.append('<title>All Outputs - BMW Sales Forecast</title>')\n",
    "        parts.append('<style>body{font-family:system-ui,Segoe UI,Roboto,Helvetica,Arial,sans-serif;margin:20px} h2{margin-top:1.2rem} figure{margin:12px 0} img{max-width:100%;height:auto;border:1px solid #ddd;padding:4px;background:#fff} .filelink{margin-bottom:8px;display:inline-block}</style>')\n",
    "        parts.append('</head>')\n",
    "        parts.append('<body>')\n",
    "        parts.append('<h1>BMW Sales Forecast ‚Äî Generated Outputs</h1>')\n",
    "        parts.append(f'<p>Repository path: {Path().resolve()}</p>')\n",
    "        if pngs:\n",
    "            parts.append('<h2>PNG Visualizations</h2>')\n",
    "            for p in pngs:\n",
    "                safe = os.path.basename(p)\n",
    "                parts.append(f'<figure><figcaption>{safe}</figcaption><img src=\"{safe}\" alt=\"{safe}\"/></figure>')\n",
    "        if htmls:\n",
    "            parts.append('<h2>Interactive HTML Outputs</h2>')\n",
    "            for h in htmls:\n",
    "                safe = os.path.basename(h)\n",
    "                parts.append(f'<div class=\"filelink\"><a href=\"{safe}\" target=\"_blank\">Open {safe} in new tab</a></div>')\n",
    "                parts.append(f'<div style=\"margin:12px 0; border:1px solid #ccc;\"><iframe src=\"{safe}\" style=\"width:100%;height:640px;border:0\"></iframe></div>')\n",
    "        parts.append('</body>')\n",
    "        parts.append('</html>')\n",
    "        html_content = '\\n'.join(parts)\n",
    "        out_path_full = OUTPUT_DIR / out_html\n",
    "        with open(out_path_full, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "        abs_path = out_path_full.resolve()\n",
    "        print(f'‚úÖ Created aggregator: {abs_path}')\n",
    "        try:\n",
    "            url = abs_path.as_uri()\n",
    "            print(f'\\nüåê Opening {out_html} in your default browser...')\n",
    "            webbrowser.open(url)\n",
    "            print(f'‚úÖ Opened aggregator: {abs_path}')\n",
    "            dash05 = (OUTPUT_DIR / '05_interactive_dashboard.html').resolve()\n",
    "            dash06 = (OUTPUT_DIR / '06_model_heatmap_interactive.html').resolve()\n",
    "            try:\n",
    "                if dash05.exists():\n",
    "                    print(f'üåê Opening dashboard: {dash05.name} in a new tab...')\n",
    "                    webbrowser.open_new_tab(dash05.as_uri())\n",
    "                else:\n",
    "                    print(f'   ‚Ä¢ {dash05} not found; skipping open for 05')\n",
    "            except Exception as e2:\n",
    "                print(f'‚ö†Ô∏è Could not open {dash05}: {e2}')\n",
    "            try:\n",
    "                if dash06.exists():\n",
    "                    print(f'üåê Opening dashboard: {dash06.name} in a new tab...')\n",
    "                    webbrowser.open_new_tab(dash06.as_uri())\n",
    "                else:\n",
    "                    print(f'   ‚Ä¢ {dash06} not found; skipping open for 06')\n",
    "            except Exception as e3:\n",
    "                print(f'‚ö†Ô∏è Could not open {dash06}: {e3}')\n",
    "            print('‚úÖ Browser open actions complete.')\n",
    "        except Exception as e:\n",
    "            print(f'‚ö†Ô∏è Could not open browser automatically: {e}')\n",
    "            print(f'   You can manually open: {abs_path}')\n",
    "# --- end aggregator ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "df = None\n",
    "df_clean = None\n",
    "df_yearly = None\n",
    "ts_data = None\n",
    "ts_years = None\n",
    "df_model_yearly = None\n",
    "df_region_yearly = None\n",
    "\n",
    "# Clean output directory\n",
    "clean_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_DATA_PROCESSING:\n",
    "    download_required_files()\n",
    "    df = load_and_explore_data(DATA_CSV_FILE)\n",
    "    df_clean = preprocess_data(df)\n",
    "    \n",
    "    if ENABLE_EXPLORATORY_ANALYSIS:\n",
    "        exploratory_data_analysis(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_TIME_SERIES:\n",
    "    df_yearly, ts_data, ts_years, df_model_yearly, df_region_yearly = aggregate_time_series(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Static Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_STATIC_PLOTS:\n",
    "    create_overview_visualizations(df_yearly, df_clean)\n",
    "    create_heatmap(df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_REPORTING:\n",
    "    # Ensure we have necessary data or defaults\n",
    "    average_sales = df_yearly['Total_Sales'].mean() if df_yearly is not None else 0\n",
    "    \n",
    "    # Create dummy data for reporting if missing\n",
    "    monthly_report = generate_monthly_report(df_clean, average_sales)\n",
    "    print(monthly_report)\n",
    "    \n",
    "    report_filename = out_path(f\"sales_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\")\n",
    "    with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(monthly_report)\n",
    "    print(f\"\\n‚úÖ Saved: {report_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_DASHBOARDS:\n",
    "    create_interactive_dashboard(ts_years, ts_data, df_yearly, df_clean)\n",
    "    create_heatmap_interactive(df_model_yearly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Aggregator & Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_AGGREGATOR:\n",
    "    create_aggregator_html()\n",
    "    zip_all_outputs()\n",
    "\n",
    "if ENABLE_REPORTING:\n",
    "    average_sales = df_yearly['Total_Sales'].mean() if df_yearly is not None else 0\n",
    "    \n",
    "    # Create dummy data for summary if missing\n",
    "    if ts_data is None:\n",
    "        ts_data = np.array([0, 0])\n",
    "    if ts_years is None:\n",
    "        ts_years = np.array([2020, 2021])\n",
    "\n",
    "    generate_final_summary(df_clean, average_sales, ts_years, ts_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
