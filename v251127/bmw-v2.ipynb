{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# BMW Sales Trend Forecasting & Alert System\n",
    "\n",
    "This notebook implements a complete analytics pipeline for BMW sales data, including:\n",
    "- Data loading and preprocessing\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Time series forecasting (ARIMA)\n",
    "- Automated alert system for underperformance\n",
    "- Static and Interactive dashboards (Plotly/Matplotlib)\n",
    "- Automated reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Configuration and Imports\n",
    "Define all necessary libraries, constants, and path configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import logging\n",
    "import requests\n",
    "import warnings\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Surpress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "# Setup Paths\n",
    "PROJECT_ROOT = Path(os.getcwd())\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'outputs'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def out_path(name: str) -> str:\n",
    "    \"\"\"Return a path inside the outputs directory as a string.\"\"\"\n",
    "    return str(OUTPUT_DIR / name)\n",
    "\n",
    "# Plotting Config\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Pandas Options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Data URLs\n",
    "DATA_CSV_URL = 'https://raw.githubusercontent.com/StephenEastham/bmw-sales-forecast/refs/heads/main/v251125/BMW-sales-data-2010-2024.csv'\n",
    "HOWTO_URL = 'https://raw.githubusercontent.com/StephenEastham/bmw-sales-forecast/refs/heads/main/how-to-test.md'\n",
    "\n",
    "DATA_CSV_FILE = 'BMW-sales-data-2010-2024.csv'\n",
    "HOWTO_FILE = 'how-to-test.md'\n",
    "\n",
    "# Forecasting parameters\n",
    "ARIMA_ORDER = (1, 1, 1)\n",
    "FORECAST_STEPS = 3\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "\n",
    "# Alert thresholds (multipliers)\n",
    "OVERALL_THRESHOLD_MULTIPLIER = 0.8\n",
    "MODEL_THRESHOLD_MULTIPLIER = 0.8\n",
    "REGION_THRESHOLD_MULTIPLIER = 0.8\n",
    "DECLINE_THRESHOLD = 0.15\n",
    "\n",
    "# Test mode (set to True to inject bad metrics for testing)\n",
    "TEST_MODE = True\n",
    "TEST_OVERALL_FORECAST_LOW = True\n",
    "TEST_MODEL_UNDERPERFORMANCE = True\n",
    "TEST_REGION_DECLINE = True\n",
    "TEST_DECLINING_TREND = True\n",
    "\n",
    "# Feature Flags\n",
    "ENABLE_DATA_PROCESSING = True\n",
    "ENABLE_EXPLORATORY_ANALYSIS = True\n",
    "ENABLE_TIME_SERIES = True\n",
    "ENABLE_STATIC_PLOTS = True\n",
    "ENABLE_ARIMA_FORECAST = True\n",
    "ENABLE_MODEL_FORECASTS = True\n",
    "ENABLE_ALERTS = True\n",
    "ENABLE_REPORTING = True\n",
    "ENABLE_DASHBOARDS = True\n",
    "ENABLE_EXPORTS = True\n",
    "ENABLE_AGGREGATOR = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Utilities\n",
    "Logging and helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(log_file='sales_alerts.log'):\n",
    "    \"\"\"Setup logging to file and console\"\"\"\n",
    "    # Remove existing handlers to avoid duplicates in notebooks\n",
    "    root = logging.getLogger()\n",
    "    if root.handlers:\n",
    "        for handler in root.handlers:\n",
    "            root.removeHandler(handler)\n",
    "            \n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(out_path(log_file)),\n",
    "            logging.StreamHandler(sys.stdout)\n",
    "        ],\n",
    "        force=True\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "def print_section(title):\n",
    "    \"\"\"Print a formatted section header\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(title)\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Processing\n",
    "Functions to download the dataset and clean it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data_file(file_name, data_url):\n",
    "    \"\"\"Download data file from URL if not exists\"\"\"\n",
    "    if not os.path.exists(file_name):\n",
    "        try:\n",
    "            print(f\"Attempting to download {file_name} from {data_url}...\")\n",
    "            response = requests.get(data_url)\n",
    "            response.raise_for_status()\n",
    "            with open(file_name, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"âœ… {file_name} downloaded successfully!\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"âŒ Failed to download {file_name}. Please ensure the URL is correct and accessible.\\nError: {e}\")\n",
    "    else:\n",
    "        print(f\"âœ… {file_name} already exists.\")\n",
    "\n",
    "def download_required_files():\n",
    "    \"\"\"Download all required data files\"\"\"\n",
    "    download_data_file(DATA_CSV_FILE, DATA_CSV_URL)\n",
    "    download_data_file(HOWTO_FILE, HOWTO_URL)\n",
    "\n",
    "def load_and_explore_data(csv_path):\n",
    "    \"\"\"Load and display dataset overview\"\"\"\n",
    "    print_section(\"ðŸ“Š DATASET OVERVIEW\")\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"\\nâœ… Data loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    display(df.head(10))\n",
    "    print(f\"\\nData summary:\")\n",
    "    display(df.describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Clean and preprocess data\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    print_section(\"ðŸ“‹ COLUMN ANALYSIS\")\n",
    "    \n",
    "    print(\"\\nColumn names:\")\n",
    "    for i, col in enumerate(df_clean.columns, 1):\n",
    "        print(f\"  {i}. '{col}' ({df_clean[col].dtype})\")\n",
    "    \n",
    "    print(f\"\\nðŸ” Missing values:\")\n",
    "    print(df_clean.isnull().sum())\n",
    "    \n",
    "    df_clean.columns = df_clean.columns.str.strip()\n",
    "\n",
    "      # Warn if any column has no non-empty values (NaN or whitespace-only strings)\n",
    "    empty_columns = []\n",
    "    for col in df_clean.columns:\n",
    "        non_na = ~df_clean[col].isna()\n",
    "        if non_na.any():\n",
    "            non_empty = df_clean.loc[non_na, col].astype(str).str.strip() != ''\n",
    "            has_values = non_empty.any()\n",
    "        else:\n",
    "            has_values = False\n",
    "        if not has_values:\n",
    "            empty_columns.append(col)\n",
    "\n",
    "    if empty_columns:\n",
    "        print(\"\\nâš ï¸ Warning: The following columns contain empty values:\")\n",
    "        for c in empty_columns:\n",
    "            print(f\"  - {c}\")\n",
    "        print(\"Consider dropping or filling these columns before further processing.\")\n",
    "    else:\n",
    "        print(\"\\nâœ… No empty columns found. All columns contain at least one non-empty value.\")\n",
    "    \n",
    "    print(f\"\\nâœ… Data preprocessing complete. Shape: {df_clean.shape}\")\n",
    "    print(f\"\\nðŸ“Š Cleaned columns:\")\n",
    "    print(df_clean.columns.tolist())\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "Initial data investigation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploratory_data_analysis(df_clean):\n",
    "    \"\"\"Perform EDA\"\"\"\n",
    "    print_section(\"ðŸ“Š EXPLORATORY DATA ANALYSIS\")\n",
    "    \n",
    "    print(\"\\nðŸŽï¸ Sales by Model (Top 10):\")\n",
    "    model_sales = df_clean.groupby('Model')['Sales_Volume'].sum().sort_values(ascending=False)\n",
    "    print(model_sales.head(10))\n",
    "    \n",
    "    print(\"\\nðŸŒ Sales by Region:\")\n",
    "    region_sales = df_clean.groupby('Region')['Sales_Volume'].sum().sort_values(ascending=False)\n",
    "    print(region_sales)\n",
    "    \n",
    "    print(\"\\nðŸ“… Sales by Year:\")\n",
    "    year_sales = df_clean.groupby('Year')['Sales_Volume'].sum().sort_values()\n",
    "    print(year_sales)\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Sales Volume Statistics:\")\n",
    "    print(df_clean['Sales_Volume'].describe())\n",
    "    \n",
    "    print(\"\\nðŸ’° Price Statistics:\")\n",
    "    print(df_clean['Price_USD'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 5. Aggregation Logic\n",
    "Aggregating data by Year, Model, and Region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_time_series(df_clean):\n",
    "    \"\"\"Aggregate data for time series analysis\"\"\"\n",
    "    print_section(\"ðŸ“ˆ TIME SERIES AGGREGATION\")\n",
    "    \n",
    "    df_yearly = df_clean.groupby('Year')['Sales_Volume'].sum().reset_index()\n",
    "    df_yearly = df_yearly.sort_values('Year')\n",
    "    df_yearly.columns = ['Year', 'Total_Sales']\n",
    "    \n",
    "    print(f\"\\nâœ… Yearly Sales Aggregation:\")\n",
    "    print(df_yearly)\n",
    "    \n",
    "    ts_data = df_yearly['Total_Sales'].values\n",
    "    ts_years = df_yearly['Year'].values\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Time Series Summary:\")\n",
    "    print(f\"   Total years: {len(ts_years)}\")\n",
    "    print(f\"   Date range: {ts_years[0]:.0f} - {ts_years[-1]:.0f}\")\n",
    "    print(f\"   Average annual sales: {ts_data.mean():,.0f}\")\n",
    "    print(f\"   Peak sales: {ts_data.max():,.0f} (Year {ts_years[np.argmax(ts_data)]:.0f})\")\n",
    "    print(f\"   Lowest sales: {ts_data.min():,.0f} (Year {ts_years[np.argmin(ts_data)]:.0f})\")\n",
    "    \n",
    "    df_yearly['YoY_Growth'] = df_yearly['Total_Sales'].pct_change() * 100\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Year-over-Year Growth:\")\n",
    "    print(df_yearly[['Year', 'Total_Sales', 'YoY_Growth']].to_string(index=False))\n",
    "    \n",
    "    df_model_yearly = df_clean.groupby(['Year', 'Model'])['Sales_Volume'].sum().reset_index()\n",
    "    df_region_yearly = df_clean.groupby(['Year', 'Region'])['Sales_Volume'].sum().reset_index()\n",
    "    \n",
    "    print(f\"\\nâœ… Model and Region time series aggregations complete\")\n",
    "    \n",
    "    return df_yearly, ts_data, ts_years, df_model_yearly, df_region_yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 6. Visualization Functions\n",
    "Static (Matplotlib) and Interactive (Plotly) visualization code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STATIC VISUALIZATIONS ---\n",
    "def create_overview_visualizations(df_yearly, df_clean):\n",
    "    \"\"\"Create static overview visualizations\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle('BMW Sales Overview (2010-2024)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Overall Sales Trend\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(df_yearly['Year'], df_yearly['Total_Sales'], marker='o', linewidth=2.5, \n",
    "             markersize=8, color='#1f77b4', label='Total Sales')\n",
    "    ax1.set_xlabel('Year', fontsize=11, fontweight='bold')\n",
    "    ax1.set_ylabel('Sales', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Total Sales Trend', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Year-over-Year Growth Rate\n",
    "    ax2 = axes[0, 1]\n",
    "    colors = ['green' if x > 0 else 'red' for x in df_yearly['YoY_Growth'].fillna(0)]\n",
    "    ax2.bar(df_yearly['Year'][1:], df_yearly['YoY_Growth'][1:], color=colors[1:], alpha=0.7)\n",
    "    ax2.set_xlabel('Year', fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel('Growth Rate (%)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Year-over-Year Growth Rate', fontsize=12, fontweight='bold')\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 3. Sales by Model (Top 10)\n",
    "    ax3 = axes[1, 0]\n",
    "    model_total = df_clean.groupby('Model')['Sales_Volume'].sum().sort_values(ascending=True).tail(10)\n",
    "    model_total.plot(kind='barh', ax=ax3, color='#ff7f0e', alpha=0.8)\n",
    "    ax3.set_xlabel('Total Sales', fontsize=11, fontweight='bold')\n",
    "    ax3.set_title('Top 10 Models by Sales', fontsize=12, fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 4. Sales by Region\n",
    "    ax4 = axes[1, 1]\n",
    "    region_total = df_clean.groupby('Region')['Sales_Volume'].sum().sort_values(ascending=False)\n",
    "    colors_region = plt.cm.Set3(np.linspace(0, 1, len(region_total)))\n",
    "    ax4.pie(region_total, labels=region_total.index, autopct='%1.1f%%', \n",
    "            colors=colors_region, startangle=90)\n",
    "    ax4.set_title('Sales Distribution by Region', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    p = out_path('01_sales_overview.png')\n",
    "    plt.savefig(p, dpi=300, bbox_inches='tight')\n",
    "    print(f\"âœ… Saved: {p}\")\n",
    "    plt.show()\n",
    "\n",
    "def create_heatmap(df_clean):\n",
    "    \"\"\"Create model-region heatmap\"\"\"\n",
    "    heatmap_data = df_clean.pivot_table(\n",
    "        values='Sales_Volume',\n",
    "        index='Model',\n",
    "        columns='Region',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    heatmap_data = heatmap_data.loc[heatmap_data.sum(axis=1).nlargest(15).index]\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap='YlOrRd', cbar_kws={'label': 'Sales'})\n",
    "    plt.title('Sales Heatmap: Model vs Region (Top 15 Models)', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Region', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Model', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    p = out_path('02_model_region_heatmap.png')\n",
    "    plt.savefig(p, dpi=300, bbox_inches='tight')\n",
    "    print(f\"âœ… Saved: {p}\")\n",
    "    plt.show()\n",
    "\n",
    "# --- INTERACTIVE VISUALIZATIONS ---\n",
    "def create_interactive_dashboard(ts_years, ts_data, future_years, future_values, \n",
    "                                 df_yearly, df_clean):\n",
    "    \"\"\"Create interactive Plotly dashboard\"\"\"\n",
    "    print_section(\"ðŸ“Š CREATING INTERACTIVE DASHBOARD\")\n",
    "    \n",
    "    fig_forecast = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Total Sales Trend & Forecast',\n",
    "            'Year-over-Year Growth',\n",
    "            'Model Performance (Top 5)',\n",
    "            'Regional Distribution'\n",
    "        ),\n",
    "        specs=[\n",
    "            [{'type': 'scatter'}, {'type': 'bar'}],\n",
    "            [{'type': 'bar'}, {'type': 'pie'}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    fig_forecast.add_trace(\n",
    "        go.Scatter(\n",
    "            x=ts_years, y=ts_data, mode='lines+markers',\n",
    "            name='Historical Sales', line=dict(color='#1f77b4', width=2),\n",
    "            marker=dict(size=8)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig_forecast.add_trace(\n",
    "        go.Scatter(\n",
    "            x=future_years, y=future_values, mode='lines+markers',\n",
    "            name='Forecast', line=dict(color='#2ca02c', width=2, dash='dash'),\n",
    "            marker=dict(size=10)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig_forecast.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_yearly['Year'][1:], y=df_yearly['YoY_Growth'][1:],\n",
    "            name='Growth Rate', marker=dict(\n",
    "                color=df_yearly['YoY_Growth'][1:],\n",
    "                colorscale='RdYlGn', showscale=False\n",
    "            )\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    top_5_models = df_clean.groupby('Model')['Sales_Volume'].sum().nlargest(5).sort_values()\n",
    "    fig_forecast.add_trace(\n",
    "        go.Bar(\n",
    "            y=top_5_models.index, x=top_5_models.values,\n",
    "            orientation='h', name='Model Sales', \n",
    "            marker=dict(color='#ff7f0e')\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    region_dist = df_clean.groupby('Region')['Sales_Volume'].sum()\n",
    "    fig_forecast.add_trace(\n",
    "        go.Pie(\n",
    "            labels=region_dist.index, values=region_dist.values,\n",
    "            name='Regions'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig_forecast.update_xaxes(title_text=\"Year\", row=1, col=1)\n",
    "    fig_forecast.update_yaxes(title_text=\"Sales\", row=1, col=1)\n",
    "    fig_forecast.update_xaxes(title_text=\"Year\", row=1, col=2)\n",
    "    fig_forecast.update_yaxes(title_text=\"Growth %\", row=1, col=2)\n",
    "    fig_forecast.update_xaxes(title_text=\"Sales\", row=2, col=1)\n",
    "    fig_forecast.update_yaxes(title_text=\"Model\", row=2, col=1)\n",
    "    \n",
    "    fig_forecast.update_layout(\n",
    "        title_text=\"BMW Sales Analytics Dashboard\",\n",
    "        showlegend=True,\n",
    "        height=900,\n",
    "        width=1400\n",
    "    )\n",
    "    \n",
    "    p = out_path('05_interactive_dashboard.html')\n",
    "    fig_forecast.write_html(p)\n",
    "    print(f\"\\nâœ… Saved: {p}\")\n",
    "    \n",
    "    # Display in notebook\n",
    "    fig_forecast.show()\n",
    "\n",
    "def create_heatmap_interactive(df_model_yearly):\n",
    "    \"\"\"Create interactive Model-Year Heatmap\"\"\"\n",
    "    heatmap_data_pivot = df_model_yearly.pivot_table(\n",
    "        values='Sales_Volume',\n",
    "        index='Model',\n",
    "        columns='Year',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    heatmap_data_pivot = heatmap_data_pivot.loc[heatmap_data_pivot.sum(axis=1).nlargest(10).index]\n",
    "    \n",
    "    fig_heatmap = go.Figure(data=go.Heatmap(\n",
    "        z=heatmap_data_pivot.values,\n",
    "        x=heatmap_data_pivot.columns,\n",
    "        y=heatmap_data_pivot.index,\n",
    "        colorscale='YlOrRd',\n",
    "        colorbar=dict(title='Sales')\n",
    "    ))\n",
    "    \n",
    "    fig_heatmap.update_layout(\n",
    "        title='BMW Model Sales Trends Over Years (Top 10 Models)',\n",
    "        xaxis_title='Year',\n",
    "        yaxis_title='Model',\n",
    "        height=600,\n",
    "        width=1200\n",
    "    )\n",
    "    \n",
    "    p = out_path('06_model_heatmap_interactive.html')\n",
    "    fig_heatmap.write_html(p)\n",
    "    print(f\"âœ… Saved: {p}\")\n",
    "    fig_heatmap.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 7. Forecasting\n",
    "ARIMA modeling and forecast visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_with_arima(ts_data, ts_years):\n",
    "    \"\"\"Forecast using ARIMA model with fallback to ExponentialSmoothing\"\"\"\n",
    "    print_section(\"ðŸ¤– ARIMA TIME SERIES FORECASTING\")\n",
    "    \n",
    "    train_size = int(len(ts_data) * TRAIN_TEST_SPLIT)\n",
    "    train_data = ts_data[:train_size]\n",
    "    test_data = ts_data[train_size:]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Data Split:\")\n",
    "    print(f\"   Train set: {len(train_data)} years\")\n",
    "    print(f\"   Test set: {len(test_data)} years\")\n",
    "    \n",
    "    print(f\"\\nðŸ”„ Fitting ARIMA{ARIMA_ORDER} model...\")\n",
    "    try:\n",
    "        arima_model = ARIMA(train_data, order=ARIMA_ORDER)\n",
    "        arima_results = arima_model.fit()\n",
    "        \n",
    "        print(\"\\n\" + arima_results.summary().as_text())\n",
    "        \n",
    "        forecast_test = arima_results.get_forecast(steps=len(test_data))\n",
    "        forecast_test_values = forecast_test.predicted_mean.values\n",
    "        forecast_test_ci = forecast_test.conf_int()\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(test_data, forecast_test_values))\n",
    "        mae = mean_absolute_error(test_data, forecast_test_values)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š MODEL PERFORMANCE (Test Set):\")\n",
    "        print(f\"   RMSE: {rmse:,.0f}\")\n",
    "        print(f\"   MAE:  {mae:,.0f}\")\n",
    "        \n",
    "        full_model = ARIMA(ts_data, order=ARIMA_ORDER)\n",
    "        full_results = full_model.fit()\n",
    "        future_forecast = full_results.get_forecast(steps=FORECAST_STEPS)\n",
    "        future_values = future_forecast.predicted_mean.values\n",
    "        future_ci = future_forecast.conf_int()\n",
    "        \n",
    "        future_years = np.array([ts_years[-1] + i for i in range(1, FORECAST_STEPS + 1)])\n",
    "        \n",
    "        print(f\"\\nðŸ”® FUTURE FORECAST (Next {FORECAST_STEPS} Years):\")\n",
    "        for year, value in zip(future_years, future_values):\n",
    "            print(f\"   Year {year:.0f}: {value:,.0f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ARIMA error: {e}\")\n",
    "        print(\"Falling back to Exponential Smoothing...\")\n",
    "        \n",
    "        try:\n",
    "            model = ExponentialSmoothing(train_data, trend='add', seasonal=None)\n",
    "            results = model.fit()\n",
    "            forecast_test_values = results.forecast(steps=len(test_data))\n",
    "            rmse = np.sqrt(mean_squared_error(test_data, forecast_test_values))\n",
    "            mae = mean_absolute_error(test_data, forecast_test_values)\n",
    "            \n",
    "            full_model = ExponentialSmoothing(ts_data, trend='add', seasonal=None)\n",
    "            full_results = full_model.fit()\n",
    "            future_values = full_results.forecast(steps=FORECAST_STEPS)\n",
    "            future_years = np.array([ts_years[-1] + i for i in range(1, FORECAST_STEPS + 1)])\n",
    "            forecast_test_ci = None\n",
    "            future_ci = None\n",
    "            \n",
    "            print(f\"âœ… Exponential Smoothing fitted successfully\")\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"âš ï¸ Fallback error: {e2}\")\n",
    "            future_values = np.repeat(ts_data[-1], FORECAST_STEPS)\n",
    "            future_years = np.array([ts_years[-1] + i for i in range(1, FORECAST_STEPS + 1)])\n",
    "            forecast_test_values = None\n",
    "            forecast_test_ci = None\n",
    "            future_ci = None\n",
    "    \n",
    "    print(f\"\\nâœ… Forecasting complete\")\n",
    "    \n",
    "    return train_size, forecast_test_values, forecast_test_ci, future_values, future_years, future_ci\n",
    "\n",
    "def calculate_model_forecasts(df_model_yearly, top_models):\n",
    "    \"\"\"Calculate forecasts for top 5 models\"\"\"\n",
    "    print_section(\"ðŸŽï¸ MODEL-SPECIFIC FORECASTS (Top 5 Models)\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Top 5 Models: {top_models}\")\n",
    "    \n",
    "    model_forecasts = {}\n",
    "    \n",
    "    for model in top_models:\n",
    "        model_data = df_model_yearly[df_model_yearly['Model'] == model].sort_values('Year')\n",
    "        \n",
    "        if len(model_data) > 2:\n",
    "            model_sales = model_data['Sales_Volume'].values\n",
    "            model_years = model_data['Year'].values\n",
    "            \n",
    "            try:\n",
    "                model_arima = ARIMA(model_sales, order=(1, 1, 1))\n",
    "                model_results = model_arima.fit()\n",
    "                model_forecast = model_results.get_forecast(steps=3)\n",
    "                forecast_values = np.asarray(model_forecast.predicted_mean)\n",
    "                \n",
    "                model_forecasts[model] = {\n",
    "                    'historical': model_sales,\n",
    "                    'forecast': forecast_values,\n",
    "                    'years': model_years,\n",
    "                    'forecast_years': np.array([model_years[-1] + i for i in range(1, 4)])\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âš ï¸ Could not forecast {model}: {e}\")\n",
    "    \n",
    "    print(f\"\\nâœ… Model forecasting complete\")\n",
    "    \n",
    "    return model_forecasts\n",
    "\n",
    "def visualize_forecast(ts_data, ts_years, train_size, forecast_test_values, forecast_test_ci, \n",
    "                       future_values, future_years, future_ci):\n",
    "    \"\"\"Visualize forecast results\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    ax.plot(ts_years, ts_data, marker='o', linewidth=2.5, markersize=8, \n",
    "            label='Historical Sales', color='#1f77b4')\n",
    "    \n",
    "    test_years = ts_years[train_size:]\n",
    "    if forecast_test_values is not None:\n",
    "        ax.plot(test_years, forecast_test_values, marker='s', linestyle='--', \n",
    "                linewidth=2, markersize=6, label='Test Forecast', color='#ff7f0e', alpha=0.8)\n",
    "    \n",
    "    ax.plot(future_years, future_values, marker='^', linestyle=':', linewidth=2.5, \n",
    "            markersize=10, label='Future Forecast', color='#2ca02c')\n",
    "    \n",
    "    # Confidence intervals\n",
    "    try:\n",
    "        if forecast_test_ci is not None:\n",
    "            ax.fill_between(test_years, \n",
    "                             forecast_test_ci.iloc[:, 0], \n",
    "                             forecast_test_ci.iloc[:, 1], \n",
    "                             alpha=0.2, color='#ff7f0e')\n",
    "        if future_ci is not None:\n",
    "            ax.fill_between(future_years, \n",
    "                             future_ci.iloc[:, 0], \n",
    "                             future_ci.iloc[:, 1], \n",
    "                             alpha=0.2, color='#2ca02c')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ax.axvline(x=ts_years[train_size-1], color='red', linestyle='--', alpha=0.5, \n",
    "               label='Train/Test Split')\n",
    "    ax.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Sales', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('BMW Total Sales: Historical Data & ARIMA Forecast', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    p = out_path('03_arima_forecast.png')\n",
    "    plt.savefig(p, dpi=300, bbox_inches='tight')\n",
    "    print(f\"âœ… Saved: {p}\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_model_forecasts(model_forecasts):\n",
    "    \"\"\"Plot forecasts for top models\"\"\"\n",
    "    print_section(\"ðŸ“Š PLOTTING MODEL FORECASTS\")\n",
    "    \n",
    "    if not model_forecasts:\n",
    "        print(\"   âš ï¸ No model forecasts to plot.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle('Top 5 BMW Models: Sales Forecast', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, (model, data) in enumerate(model_forecasts.items()):\n",
    "        if idx >= 5: break\n",
    "        \n",
    "        ax = axes[idx]\n",
    "        ax.plot(data['years'], data['historical'], marker='o', linewidth=2, label='Historical')\n",
    "        ax.plot(data['forecast_years'], data['forecast'], \n",
    "               marker='^', linestyle='--', linewidth=2, color='red', label='Forecast')\n",
    "        ax.set_title(f'Model: {model}', fontweight='bold')\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Sales')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(model_forecasts), len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    p = out_path('04_model_forecasts.png')\n",
    "    plt.savefig(p, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nâœ… Saved: {p}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 8. Alert System\n",
    "Logic to check forecasts against thresholds and trigger alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalesAlertSystem:\n",
    "    \"\"\"Automated alert system for underperforming models and regions\"\"\"\n",
    "    \n",
    "    def __init__(self, threshold, model_thresholds=None, region_thresholds=None):\n",
    "        self.threshold = threshold\n",
    "        self.model_thresholds = model_thresholds or {}\n",
    "        self.region_thresholds = region_thresholds or {}\n",
    "        self.alerts = []\n",
    "        self.logger = setup_logger()\n",
    "    \n",
    "    def check_overall_forecast(self, forecast_values, threshold):\n",
    "        \"\"\"Check if forecasted sales fall below threshold\"\"\"\n",
    "        alerts = []\n",
    "        for i, value in enumerate(forecast_values):\n",
    "            if value < threshold:\n",
    "                alert = {\n",
    "                    'type': 'OVERALL_SALES',\n",
    "                    'severity': 'HIGH',\n",
    "                    'message': f'ALERT: Forecasted sales for year {i+1} ({value:,.0f}) '\n",
    "                               f'falls below threshold ({threshold:,.0f})',\n",
    "                    'forecast_value': value,\n",
    "                    'threshold': threshold,\n",
    "                    'gap': threshold - value\n",
    "                }\n",
    "                alerts.append(alert)\n",
    "                self.logger.warning(alert['message'])\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def check_model_performance(self, model_data, model_name, threshold):\n",
    "        \"\"\"Check if model sales are underperforming\"\"\"\n",
    "        alerts = []\n",
    "        recent_sales = model_data['historical'][-1] if len(model_data['historical']) > 0 else 0\n",
    "        \n",
    "        if recent_sales < threshold:\n",
    "            alert = {\n",
    "                'type': 'MODEL_UNDERPERFORMANCE',\n",
    "                'severity': 'MEDIUM',\n",
    "                'model': model_name,\n",
    "                'message': f'ALERT: Model {model_name} recent sales ({recent_sales:,.0f}) '\n",
    "                           f'below threshold ({threshold:,.0f})',\n",
    "                'recent_sales': recent_sales,\n",
    "                'threshold': threshold,\n",
    "                'gap': threshold - recent_sales\n",
    "            }\n",
    "            alerts.append(alert)\n",
    "            self.logger.warning(alert['message'])\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def check_declining_trend(self, sales_history, item_name, decline_threshold=0.1):\n",
    "        \"\"\"Check if sales are in decline\"\"\"\n",
    "        if len(sales_history) < 2:\n",
    "            return []\n",
    "        \n",
    "        alerts = []\n",
    "        decline_rate = (sales_history[-2] - sales_history[-1]) / sales_history[-2]\n",
    "        \n",
    "        if decline_rate > decline_threshold:\n",
    "            alert = {\n",
    "                'type': 'DECLINING_TREND',\n",
    "                'severity': 'MEDIUM',\n",
    "                'item': item_name,\n",
    "                'message': f'ALERT: {item_name} showing {decline_rate*100:.1f}% decline',\n",
    "                'decline_rate': decline_rate\n",
    "            }\n",
    "            alerts.append(alert)\n",
    "            self.logger.warning(alert['message'])\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def generate_alert_report(self):\n",
    "        \"\"\"Generate summary report of all alerts\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SALES ALERT REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        if not self.alerts:\n",
    "            print(\"\\nâœ… No alerts triggered! All metrics within acceptable range.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nTotal Alerts: {len(self.alerts)}\\n\")\n",
    "        \n",
    "        high_severity = [a for a in self.alerts if a.get('severity') == 'HIGH']\n",
    "        medium_severity = [a for a in self.alerts if a.get('severity') == 'MEDIUM']\n",
    "        \n",
    "        if high_severity:\n",
    "            print(\"HIGH SEVERITY ALERTS:\")\n",
    "            for alert in high_severity:\n",
    "                print(f\"   - {alert['message']}\")\n",
    "        \n",
    "        if medium_severity:\n",
    "            print(\"\\nMEDIUM SEVERITY ALERTS:\")\n",
    "            for alert in medium_severity:\n",
    "                print(f\"   - {alert['message']}\")\n",
    "\n",
    "def setup_alert_system(df_clean, df_yearly, top_models):\n",
    "    \"\"\"Setup alert thresholds and system\"\"\"\n",
    "    \n",
    "    print_section(\"âš ï¸ ALERT THRESHOLD CONFIGURATION\")\n",
    "    \n",
    "    average_sales = df_yearly['Total_Sales'].mean()\n",
    "    ALERT_THRESHOLD_OVERALL = average_sales * OVERALL_THRESHOLD_MULTIPLIER\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Overall Metrics:\")\n",
    "    print(f\"   Average historical sales: {average_sales:,.0f}\")\n",
    "    print(f\"   Alert threshold (80%): {ALERT_THRESHOLD_OVERALL:,.0f}\")\n",
    "    \n",
    "    model_thresholds = {}\n",
    "    print(f\"\\nðŸŽï¸ Model-Specific Alert Thresholds (Top 5):\")\n",
    "    for model in top_models:\n",
    "        model_avg = df_clean[df_clean['Model'] == model]['Sales_Volume'].mean()\n",
    "        model_threshold = model_avg * MODEL_THRESHOLD_MULTIPLIER\n",
    "        model_thresholds[model] = model_threshold\n",
    "        print(f\"   {model}: {model_threshold:,.0f}\")\n",
    "    \n",
    "    region_thresholds = {}\n",
    "    unique_regions = df_clean['Region'].unique()\n",
    "    print(f\"\\nðŸŒ Region-Specific Alert Thresholds:\")\n",
    "    for region in unique_regions:\n",
    "        region_avg = df_clean[df_clean['Region'] == region]['Sales_Volume'].mean()\n",
    "        region_threshold = region_avg * REGION_THRESHOLD_MULTIPLIER\n",
    "        region_thresholds[region] = region_threshold\n",
    "        print(f\"   {region}: {region_threshold:,.0f}\")\n",
    "    \n",
    "    return SalesAlertSystem(\n",
    "        threshold=ALERT_THRESHOLD_OVERALL,\n",
    "        model_thresholds=model_thresholds,\n",
    "        region_thresholds=region_thresholds\n",
    "    ), ALERT_THRESHOLD_OVERALL, model_thresholds, region_thresholds, unique_regions\n",
    "\n",
    "# --- ALERT HELPERS ---\n",
    "def run_alert_checks(alert_system, future_values, model_forecasts, df_region_yearly,\n",
    "                     ALERT_THRESHOLD_OVERALL, model_thresholds, region_thresholds,\n",
    "                     unique_regions, latest_year):\n",
    "    \"\"\"Run all alert checks and return populated alert system\"\"\"\n",
    "    overall_alerts = alert_system.check_overall_forecast(future_values, ALERT_THRESHOLD_OVERALL)\n",
    "    alert_system.alerts.extend(overall_alerts)\n",
    "    \n",
    "    for model, forecast_data in model_forecasts.items():\n",
    "        model_alerts = alert_system.check_model_performance(\n",
    "            forecast_data, model, \n",
    "            model_thresholds.get(model, ALERT_THRESHOLD_OVERALL)\n",
    "        )\n",
    "        alert_system.alerts.extend(model_alerts)\n",
    "        \n",
    "        decline_alerts = alert_system.check_declining_trend(\n",
    "            forecast_data['historical'], model, decline_threshold=DECLINE_THRESHOLD\n",
    "        )\n",
    "        alert_system.alerts.extend(decline_alerts)\n",
    "    \n",
    "    for region in unique_regions:\n",
    "        region_latest = df_region_yearly[\n",
    "            (df_region_yearly['Region'] == region) & \n",
    "            (df_region_yearly['Year'] == latest_year)\n",
    "        ]['Sales_Volume'].values\n",
    "        \n",
    "        if len(region_latest) > 0:\n",
    "            region_threshold = region_thresholds.get(region, ALERT_THRESHOLD_OVERALL)\n",
    "            if region_latest[0] < region_threshold:\n",
    "                alert_system.alerts.append({\n",
    "                    'type': 'REGION_UNDERPERFORMANCE',\n",
    "                    'severity': 'MEDIUM',\n",
    "                    'region': region,\n",
    "                    'message': f'ALERT: Region {region} sales ({region_latest[0]:,.0f}) '\n",
    "                               f'below threshold ({region_threshold:,.0f})',\n",
    "                })\n",
    "    \n",
    "    return alert_system\n",
    "\n",
    "\n",
    "def inject_test_metrics(future_values, model_forecasts, df_region_yearly,\n",
    "                        ALERT_THRESHOLD_OVERALL, model_thresholds, region_thresholds,\n",
    "                        latest_year, unique_regions, top_models):\n",
    "    \"\"\"Inject bad metrics for testing alert system\"\"\"\n",
    "    print(\"\\n\" + \"ðŸ§ª TEST MODE ENABLED - Injecting bad metrics for alert testing\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ§ª TEST MODE: INJECTING BAD METRICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    original_future_values = future_values.copy()\n",
    "    \n",
    "    # Scenario 1: Make overall forecast drop below threshold\n",
    "    if TEST_OVERALL_FORECAST_LOW:\n",
    "        future_values_test = np.array([\n",
    "            ALERT_THRESHOLD_OVERALL * 0.6,\n",
    "            ALERT_THRESHOLD_OVERALL * 0.7,\n",
    "            ALERT_THRESHOLD_OVERALL * 0.5\n",
    "        ])\n",
    "        future_values = future_values_test\n",
    "        print(f\"\\nâœ“ Overall Forecast: Set to 50-70% of threshold\")\n",
    "        print(f\"  Original: {original_future_values}\")\n",
    "        print(f\"  Test: {future_values_test}\")\n",
    "    \n",
    "    # Scenario 2: Make top models underperform\n",
    "    if TEST_MODEL_UNDERPERFORMANCE:\n",
    "        for model in top_models:\n",
    "            model_forecasts[model]['historical'] = model_forecasts[model]['historical'].copy()\n",
    "            model_forecasts[model]['historical'][-1] = model_thresholds[model] * 0.5\n",
    "            print(f\"âœ“ Model '{model}': Recent sales reduced to 50% of threshold\")\n",
    "    \n",
    "    # Scenario 3: Create steep regional decline\n",
    "    if TEST_REGION_DECLINE:\n",
    "        for region in unique_regions:\n",
    "            df_region_yearly.loc[\n",
    "                (df_region_yearly['Region'] == region) & \n",
    "                (df_region_yearly['Year'] == latest_year), \n",
    "                'Sales_Volume'\n",
    "            ] = region_thresholds[region] * 0.5\n",
    "        print(f\"âœ“ Regional Sales: Set to 50% of threshold for latest year\")\n",
    "    \n",
    "    # Scenario 4: Create declining trend\n",
    "    if TEST_DECLINING_TREND:\n",
    "        for model in top_models[:2]:\n",
    "            if model in model_forecasts:\n",
    "                hist = model_forecasts[model]['historical'].copy()\n",
    "                if len(hist) >= 2:\n",
    "                    hist[-1] = hist[-2] * 0.8\n",
    "                    model_forecasts[model]['historical'] = hist\n",
    "                    print(f\"âœ“ Model '{model}': Created 20% decline in recent years\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"All test metrics injected. Re-running alert checks below...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return future_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 9. Reporting & HTML Aggregation\n",
    "Generate text reports and the HTML hub page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_monthly_report(alerts, forecast_data, df_clean, average_sales, \n",
    "                           future_values, ts_data, future_years, ALERT_THRESHOLD_OVERALL):\n",
    "    \"\"\"Generate comprehensive monthly report\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now()\n",
    "    \n",
    "    report = f\"\"\"\n",
    "{'='*80}\n",
    "BMW SALES ANALYTICS - MONTHLY REPORT\n",
    "Generated: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "{'='*80}\n",
    "\n",
    "1. EXECUTIVE SUMMARY\n",
    "{'â”€'*80}\n",
    "   â€¢ Report Period: {timestamp.strftime('%B %Y')}\n",
    "   â€¢ Total Forecasted Sales (Next Quarter): {future_values.mean():,.0f}\n",
    "   â€¢ Alert Threshold: {ALERT_THRESHOLD_OVERALL:,.0f}\n",
    "   â€¢ Number of Active Alerts: {len(alerts)}\n",
    "\n",
    "2. KEY METRICS\n",
    "{'â”€'*80}\n",
    "   â€¢ Historical Average Sales: {average_sales:,.0f}\n",
    "   â€¢ Current Forecast Trend: {'INCREASING' if future_values[-1] > ts_data[-1] else 'DECREASING'}\n",
    "   â€¢ Year-over-Year Change: {((ts_data[-1] - ts_data[-2]) / ts_data[-2] * 100):+.2f}%\n",
    "\n",
    "3. ALERTS & ACTION ITEMS\n",
    "{'â”€'*80}\n",
    "\"\"\"\n",
    "    \n",
    "    if alerts:\n",
    "        for i, alert in enumerate(alerts, 1):\n",
    "            report += f\"\\n   Alert {i}: {alert['message']}\"\n",
    "            if 'gap' in alert:\n",
    "                report += f\"\\n              Gap from threshold: {alert['gap']:,.0f}\"\n",
    "    else:\n",
    "        report += \"\\n   No alerts triggered. All metrics within acceptable range.\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "\n",
    "4. FORECAST OUTLOOK (NEXT 3 YEARS)\n",
    "{'â”€'*80}\n",
    "\"\"\"\n",
    "    \n",
    "    for year, value in zip(future_years, future_values):\n",
    "        trend = \"UP\" if value > ts_data[-1] else \"DOWN\"\n",
    "        report += f\"\\n   {year:.0f}: {value:,.0f} [{trend}]\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "\n",
    "5. MODEL PERFORMANCE (Top 5)\n",
    "{'â”€'*80}\n",
    "\"\"\"\n",
    "    \n",
    "    top_performers = df_clean.groupby('Model')['Sales_Volume'].sum().nlargest(5)\n",
    "    for i, (model, sales) in enumerate(top_performers.items(), 1):\n",
    "        report += f\"\\n   {i}. {model}: {sales:,.0f}\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "\n",
    "6. REGIONAL PERFORMANCE\n",
    "{'â”€'*80}\n",
    "\"\"\"\n",
    "    \n",
    "    by_region = df_clean.groupby('Region')['Sales_Volume'].sum().sort_values(ascending=False)\n",
    "    for region, sales in by_region.items():\n",
    "        pct = (sales / by_region.sum() * 100)\n",
    "        report += f\"\\n   â€¢ {region}: {sales:,.0f} ({pct:.1f}%)\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "\n",
    "7. RECOMMENDATIONS\n",
    "{'â”€'*80}\n",
    "   â€¢ Monitor underperforming models closely\n",
    "   â€¢ Invest in high-growth regions\n",
    "   â€¢ Adjust inventory based on forecasts\n",
    "   â€¢ Review market conditions quarterly\n",
    "\n",
    "{'='*80}\n",
    "END OF REPORT\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "def export_data(future_years, future_values, ALERT_THRESHOLD_OVERALL, alert_system, \n",
    "                model_forecasts, model_thresholds, df_clean):\n",
    "    \"\"\"Export forecast data and alerts\"\"\"\n",
    "    print_section(\"ðŸ“Š EXPORTING FORECAST DATA\")\n",
    "    \n",
    "    forecast_export = pd.DataFrame({\n",
    "        'Year': future_years.astype(int),\n",
    "        'Forecasted_Sales': future_values.round(0).astype(int),\n",
    "        'Threshold': [int(ALERT_THRESHOLD_OVERALL)] * len(future_years),\n",
    "        'Below_Threshold': future_values < ALERT_THRESHOLD_OVERALL\n",
    "    })\n",
    "    \n",
    "    print(\"\\nðŸ“Š Forecast Export:\")\n",
    "    print(forecast_export)\n",
    "    \n",
    "    forecast_export.to_csv(out_path('forecast_next_3_years.csv'), index=False)\n",
    "    print(f\"\\nâœ… Saved: {out_path('forecast_next_3_years.csv')}\")\n",
    "    \n",
    "    if alert_system.alerts:\n",
    "        alerts_df = pd.DataFrame(alert_system.alerts)\n",
    "        alerts_df.to_csv(out_path('active_alerts.csv'), index=False)\n",
    "        print(f\"âœ… Saved: {out_path('active_alerts.csv')}\")\n",
    "    \n",
    "    model_forecast_df = []\n",
    "    for model, data in model_forecasts.items():\n",
    "        for i, (year, value) in enumerate(zip(data['forecast_years'], data['forecast'])):\n",
    "            model_forecast_df.append({\n",
    "                'Model': model,\n",
    "                'Year': int(year),\n",
    "                'Forecasted_Sales': int(value),\n",
    "                'Threshold': int(model_thresholds.get(model, ALERT_THRESHOLD_OVERALL))\n",
    "            })\n",
    "    \n",
    "    if model_forecast_df:\n",
    "        model_forecast_export = pd.DataFrame(model_forecast_df)\n",
    "        model_forecast_export.to_csv(out_path('model_forecasts_export.csv'), index=False)\n",
    "        print(f\"âœ… Saved: {out_path('model_forecasts_export.csv')}\")\n",
    "    \n",
    "    print(\"\\nâœ… Data export complete\")\n",
    "\n",
    "\n",
    "def generate_final_summary(df_clean, average_sales, ts_years, ts_data, future_years, \n",
    "                          future_values, model_forecasts, alert_system):\n",
    "    \"\"\"Generate and save final summary\"\"\"\n",
    "    \n",
    "    summary = f\"\"\"\n",
    "{'='*80}\n",
    "BMW SALES TREND FORECASTING & ALERT SYSTEM - PROJECT COMPLETE\n",
    "{'='*80}\n",
    "\n",
    "ANALYSIS COMPLETED:\n",
    "\n",
    "1. Data Overview:\n",
    "   â€¢ Total records analyzed: {len(df_clean):,}\n",
    "   â€¢ Time period: {df_clean['Year'].min():.0f} - {df_clean['Year'].max():.0f}\n",
    "   â€¢ Models tracked: {df_clean['Model'].nunique()}\n",
    "   â€¢ Regions tracked: {df_clean['Region'].nunique()}\n",
    "\n",
    "2. Historical Performance:\n",
    "   â€¢ Average annual sales: {average_sales:,.0f}\n",
    "   â€¢ Peak sales year: {ts_years[np.argmax(ts_data)]:.0f} ({ts_data.max():,.0f})\n",
    "   â€¢ Lowest sales year: {ts_years[np.argmin(ts_data)]:.0f} ({ts_data.min():,.0f})\n",
    "   â€¢ Trend: {'GROWING' if ts_data[-1] > ts_data[0] else 'DECLINING'}\n",
    "\n",
    "3. Forecast Results (Next 3 Years):\n",
    "   â€¢ Year 1 ({future_years[0]:.0f}): {future_values[0]:,.0f}\n",
    "   â€¢ Year 2 ({future_years[1]:.0f}): {future_values[1]:,.0f}\n",
    "   â€¢ Year 3 ({future_years[2]:.0f}): {future_values[2]:,.0f}\n",
    "   â€¢ Average forecast: {future_values.mean():,.0f}\n",
    "\n",
    "4. Alert System Status:\n",
    "   â€¢ Active alerts: {len(alert_system.alerts)}\n",
    "   â€¢ High severity: {len([a for a in alert_system.alerts if a.get('severity') == 'HIGH'])}\n",
    "   â€¢ Medium severity: {len([a for a in alert_system.alerts if a.get('severity') == 'MEDIUM'])}\n",
    "\n",
    "5. Visualizations Generated:\n",
    "   [OK] 01_sales_overview.png - Overview charts (4-panel analysis)\n",
    "   [OK] 02_model_region_heatmap.png - Performance matrix\n",
    "   [OK] 03_arima_forecast.png - Forecast visualization\n",
    "   [OK] 04_model_forecasts.png - Individual model forecasts (Top 5)\n",
    "   [OK] 05_interactive_dashboard.html - Main interactive dashboard\n",
    "   [OK] 06_model_heatmap_interactive.html - Interactive heatmap\n",
    "   [OK] 07_all_outputs.html - Aggregated outputs page\n",
    "\n",
    "6. Data Files Generated:\n",
    "   [OK] forecast_next_3_years.csv - Forecast data\n",
    "   [OK] active_alerts.csv - Current alerts\n",
    "   [OK] model_forecasts_export.csv - Model-specific forecasts\n",
    "   [OK] sales_report_[timestamp].txt - Detailed report\n",
    "   [OK] sales_alerts.log - Alert log file\n",
    "   [OK] ANALYSIS_SUMMARY.txt - This summary\n",
    "\n",
    "7. Top Insights:\n",
    "   â€¢ Top Model: {df_clean.groupby('Model')['Sales_Volume'].sum().idxmax()}\n",
    "   â€¢ Top Region: {df_clean.groupby('Region')['Sales_Volume'].sum().idxmax()}\n",
    "   â€¢ Forecast Trend: {'POSITIVE' if future_values[-1] > ts_data[-1] else 'NEGATIVE'}\n",
    "   â€¢ Model Count: {len(model_forecasts)} models forecasted\n",
    "   â€¢ Alert Coverage: Model + Region-level monitoring active\n",
    "\n",
    "8. Next Steps:\n",
    "   [DONE] Review interactive dashboard for detailed insights\n",
    "   [DONE] Check sales_alerts.log for all alert notifications\n",
    "   [DONE] Distribute monthly report to stakeholders\n",
    "   [READY] Set up automated email alerts (integration ready)\n",
    "   [READY] Schedule quarterly review and threshold adjustments\n",
    "   [READY] Monitor model performance in real-time\n",
    "\n",
    "{'='*80}\n",
    "PROJECT STATUS: COMPLETE & READY FOR PRODUCTION\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "    \n",
    "    print(summary)\n",
    "    \n",
    "    with open(out_path('ANALYSIS_SUMMARY.txt'), 'w', encoding='utf-8') as f:\n",
    "        f.write(summary)\n",
    "\n",
    "    print(f\"\\n[OK] Saved: {out_path('ANALYSIS_SUMMARY.txt')}\")\n",
    "\n",
    "def create_aggregator_html():\n",
    "    \"\"\"Create aggregator HTML page for all outputs\"\"\"\n",
    "    out_html = '07_all_outputs.html'\n",
    "    # Look for generated PNGs/HTMLs inside the outputs directory\n",
    "    pngs = sorted([str(p) for p in OUTPUT_DIR.glob('*.png')])\n",
    "    exclude_names = {out_html, 'commit_messages-can-change-values.html'}\n",
    "    htmls = sorted([str(p) for p in OUTPUT_DIR.glob('*.html') if os.path.basename(p) not in exclude_names])\n",
    "    \n",
    "    if not pngs and not htmls:\n",
    "        print('No output PNG or HTML files found in the current directory.')\n",
    "    else:\n",
    "        parts = []\n",
    "        parts.append('<!doctype html>')\n",
    "        parts.append('<html lang=\"en\">')\n",
    "        parts.append('<head>')\n",
    "        parts.append('<meta charset=\"utf-8\"/>')\n",
    "        parts.append('<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/>')\n",
    "        parts.append('<title>All Outputs - BMW Sales Forecast</title>')\n",
    "        parts.append('<style>body{font-family:system-ui,Segoe UI,Roboto,Helvetica,Arial,sans-serif;margin:20px} h2{margin-top:1.2rem} figure{margin:12px 0} img{max-width:100%;height:auto;border:1px solid #ddd;padding:4px;background:#fff} .filelink{margin-bottom:8px;display:inline-block}</style>')\n",
    "        parts.append('</head>')\n",
    "        parts.append('<body>')\n",
    "        parts.append('<h1>BMW Sales Forecast â€” Generated Outputs</h1>')\n",
    "        parts.append(f'<p>Repository path: {Path().resolve()}</p>')\n",
    "        \n",
    "        if pngs:\n",
    "            parts.append('<h2>PNG Visualizations</h2>')\n",
    "            for p in pngs:\n",
    "                safe = os.path.basename(p)\n",
    "                parts.append(f'<figure><figcaption>{safe}</figcaption><img src=\"{safe}\" alt=\"{safe}\"/></figure>')\n",
    "        \n",
    "        if htmls:\n",
    "            parts.append('<h2>Interactive HTML Outputs</h2>')\n",
    "            for h in htmls:\n",
    "                safe = os.path.basename(h)\n",
    "                parts.append(f'<div class=\"filelink\"><a href=\"{safe}\" target=\"_blank\">Open {safe} in new tab</a></div>')\n",
    "                parts.append(f'<div style=\"margin:12px 0; border:1px solid #ccc;\"><iframe src=\"{safe}\" style=\"width:100%;height:640px;border:0\"></iframe></div>')\n",
    "        \n",
    "        parts.append('</body>')\n",
    "        parts.append('</html>')\n",
    "        \n",
    "        html_content = '\\n'.join(parts)\n",
    "        out_path_full = OUTPUT_DIR / out_html\n",
    "        with open(out_path_full, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "\n",
    "        abs_path = out_path_full.resolve()\n",
    "        print(f'âœ… Created aggregator: {abs_path}')\n",
    "\n",
    "        # Automatically open the aggregator and the two interactive dashboards\n",
    "        try:\n",
    "            url = abs_path.as_uri()\n",
    "            print(f'\\nðŸŒ Opening {out_html} in your default browser...')\n",
    "            webbrowser.open(url)\n",
    "            print(f'âœ… Opened aggregator: {abs_path}')\n",
    "\n",
    "            # Open the interactive dashboards in separate tabs if they exist\n",
    "            dash05 = (OUTPUT_DIR / '05_interactive_dashboard.html').resolve()\n",
    "            dash06 = (OUTPUT_DIR / '06_model_heatmap_interactive.html').resolve()\n",
    "\n",
    "            try:\n",
    "                if dash05.exists():\n",
    "                    print(f'ðŸŒ Opening dashboard: {dash05.name} in a new tab...')\n",
    "                    webbrowser.open_new_tab(dash05.as_uri())\n",
    "                else:\n",
    "                    print(f'   â€¢ {dash05} not found; skipping open for 05')\n",
    "            except Exception as e2:\n",
    "                print(f'âš ï¸ Could not open {dash05}: {e2}')\n",
    "\n",
    "            try:\n",
    "                if dash06.exists():\n",
    "                    print(f'ðŸŒ Opening dashboard: {dash06.name} in a new tab...')\n",
    "                    webbrowser.open_new_tab(dash06.as_uri())\n",
    "                else:\n",
    "                    print(f'   â€¢ {dash06} not found; skipping open for 06')\n",
    "            except Exception as e3:\n",
    "                print(f'âš ï¸ Could not open {dash06}: {e3}')\n",
    "\n",
    "            print('âœ… Browser open actions complete.')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'âš ï¸ Could not open browser automatically: {e}')\n",
    "            print(f'   You can manually open: {abs_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 10. Zip all outputs\n",
    "Put all outputs in .zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_all_outputs(zip_filename=None, patterns=('*.png','*.html','*.csv','*.txt')):\n",
    "    \"\"\"Create a zip archive of generated outputs in `OUTPUT_DIR`.\n",
    "\n",
    "    - `zip_filename` can be a str path or None (defaults to outputs/all_outputs.zip).\n",
    "    - `patterns` is an iterable of glob patterns to include.\n",
    "    \"\"\"\n",
    "    from zipfile import ZipFile, ZIP_DEFLATED\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "\n",
    "    if zip_filename is None:\n",
    "        zip_path = OUTPUT_DIR / 'all_outputs.zip'\n",
    "    else:\n",
    "        zip_path = Path(zip_filename)\n",
    "        if not zip_path.is_absolute():\n",
    "            zip_path = OUTPUT_DIR / zip_path\n",
    "\n",
    "    # Ensure OUTPUT_DIR exists\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    added = 0\n",
    "    try:\n",
    "        with ZipFile(zip_path, 'w', ZIP_DEFLATED) as zf:\n",
    "            for pat in patterns:\n",
    "                for p in OUTPUT_DIR.glob(pat):\n",
    "                    if p.is_file():\n",
    "                        zf.write(p, arcname=p.name)\n",
    "                        added += 1\n",
    "        print(f\"âœ… Created zip: {zip_path.resolve()} ({added} files)\")\n",
    "        return zip_path\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error while creating zip: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print_section(\"BMW SALES TREND FORECASTING & ALERT SYSTEM\")\n",
    "    \n",
    "    print(f\"Python: {sys.executable}\")\n",
    "    print(f\"Version: {sys.version.splitlines()[0]}\")\n",
    "\n",
    "    # Initialize variables to None/Empty to handle feature flags\n",
    "    df = None\n",
    "    df_clean = None\n",
    "    df_yearly = None\n",
    "    ts_data = None\n",
    "    ts_years = None\n",
    "    df_model_yearly = None\n",
    "    df_region_yearly = None\n",
    "    train_size = None\n",
    "    forecast_test_values = None\n",
    "    forecast_test_ci = None\n",
    "    future_values = None\n",
    "    future_years = None\n",
    "    future_ci = None\n",
    "    top_models = []\n",
    "    model_forecasts = {}\n",
    "    alert_system = None\n",
    "    ALERT_THRESHOLD_OVERALL = 0\n",
    "    model_thresholds = {}\n",
    "    region_thresholds = {}\n",
    "    unique_regions = []\n",
    "    \n",
    "    # ===== DATA LOADING & PREPROCESSING =====\n",
    "    if ENABLE_DATA_PROCESSING:\n",
    "        download_required_files()\n",
    "        df = load_and_explore_data(DATA_CSV_FILE)\n",
    "        df_clean = preprocess_data(df)\n",
    "        \n",
    "        if ENABLE_EXPLORATORY_ANALYSIS:\n",
    "            exploratory_data_analysis(df_clean)\n",
    "    \n",
    "    # ===== TIME SERIES AGGREGATION =====\n",
    "    if ENABLE_TIME_SERIES and df_clean is not None:\n",
    "        df_yearly, ts_data, ts_years, df_model_yearly, df_region_yearly = aggregate_time_series(df_clean)\n",
    "    \n",
    "    # ===== STATIC VISUALIZATIONS =====\n",
    "    if ENABLE_STATIC_PLOTS and df_yearly is not None and df_clean is not None:\n",
    "        create_overview_visualizations(df_yearly, df_clean)\n",
    "        create_heatmap(df_clean)\n",
    "    \n",
    "    # ===== ARIMA FORECASTING =====\n",
    "    if ENABLE_ARIMA_FORECAST and ts_data is not None and ts_years is not None:\n",
    "        train_size, forecast_test_values, forecast_test_ci, future_values, future_years, future_ci = \\\n",
    "            forecast_with_arima(ts_data, ts_years)\n",
    "        visualize_forecast(ts_data, ts_years, train_size, forecast_test_values, forecast_test_ci, \n",
    "                        future_values, future_years, future_ci)\n",
    "    \n",
    "    # ===== MODEL-SPECIFIC FORECASTS =====\n",
    "    if ENABLE_MODEL_FORECASTS and df_clean is not None and df_model_yearly is not None:\n",
    "        top_models = df_clean.groupby('Model')['Sales_Volume'].sum().nlargest(5).index.tolist()\n",
    "        model_forecasts = calculate_model_forecasts(df_model_yearly, top_models)\n",
    "        plot_model_forecasts(model_forecasts)\n",
    "    \n",
    "    # ===== ALERT SYSTEM SETUP =====\n",
    "    if ENABLE_ALERTS and df_clean is not None and df_yearly is not None and df_region_yearly is not None:\n",
    "        alert_system, ALERT_THRESHOLD_OVERALL, model_thresholds, region_thresholds, unique_regions = \\\n",
    "            setup_alert_system(df_clean, df_yearly, top_models)\n",
    "        \n",
    "        # ===== RUN ALERT CHECKS =====\n",
    "        latest_year = df_region_yearly['Year'].max()\n",
    "        alert_system = run_alert_checks(\n",
    "            alert_system, future_values, model_forecasts, df_region_yearly,\n",
    "            ALERT_THRESHOLD_OVERALL, model_thresholds, region_thresholds,\n",
    "            unique_regions, latest_year\n",
    "        )\n",
    "        alert_system.generate_alert_report()\n",
    "        print(f\"\\nâœ… Alert system initialized with {len(alert_system.alerts)} alerts\")\n",
    "        \n",
    "        # ===== TEST MODE: INJECT BAD METRICS =====\n",
    "        if TEST_MODE:\n",
    "            future_values = inject_test_metrics(\n",
    "                future_values, model_forecasts, df_region_yearly,\n",
    "                ALERT_THRESHOLD_OVERALL, model_thresholds, region_thresholds,\n",
    "                latest_year, unique_regions, top_models\n",
    "            )\n",
    "            \n",
    "            # Re-run alert checks with injected data\n",
    "            alert_system.alerts = []\n",
    "            alert_system = run_alert_checks(\n",
    "                alert_system, future_values, model_forecasts, df_region_yearly,\n",
    "                ALERT_THRESHOLD_OVERALL, model_thresholds, region_thresholds,\n",
    "                unique_regions, latest_year\n",
    "            )\n",
    "            alert_system.generate_alert_report()\n",
    "            print(f\"\\nâœ… Alert system re-initialized with {len(alert_system.alerts)} TRIGGERED ALERTS\")\n",
    "    \n",
    "    # ===== REPORTING & VISUALIZATION =====\n",
    "    if ENABLE_REPORTING and df_clean is not None:\n",
    "        # Ensure we have necessary data or defaults\n",
    "        alerts = alert_system.alerts if alert_system else []\n",
    "        average_sales = df_yearly['Total_Sales'].mean() if df_yearly is not None else 0\n",
    "        \n",
    "        # Create dummy data for reporting if missing\n",
    "        if ts_data is None:\n",
    "            ts_data = np.array([0, 0])\n",
    "        if future_values is None:\n",
    "            future_values = np.array([0, 0, 0])\n",
    "        if future_years is None:\n",
    "            future_years = np.array([datetime.now().year + i for i in range(1, 4)])\n",
    "            \n",
    "        monthly_report = generate_monthly_report(\n",
    "            alerts, model_forecasts, df_clean, average_sales, \n",
    "            future_values, ts_data, future_years, ALERT_THRESHOLD_OVERALL\n",
    "        )\n",
    "        print(monthly_report)\n",
    "        \n",
    "        report_filename = out_path(f\"sales_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\")\n",
    "        with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(monthly_report)\n",
    "        print(f\"\\nâœ… Saved: {report_filename}\")\n",
    "    \n",
    "    # ===== INTERACTIVE DASHBOARDS =====\n",
    "    if ENABLE_DASHBOARDS and ts_years is not None and ts_data is not None and df_yearly is not None and df_clean is not None and df_model_yearly is not None:\n",
    "        create_interactive_dashboard(ts_years, ts_data, future_years, future_values, \n",
    "                                    df_yearly, df_clean)\n",
    "        create_heatmap_interactive(df_model_yearly)\n",
    "    \n",
    "    # ===== DATA EXPORT =====\n",
    "    if ENABLE_EXPORTS and df_clean is not None:\n",
    "        if alert_system is None:\n",
    "            # Create a dummy object with an alerts attribute\n",
    "            class DummyAlertSystem:\n",
    "                def __init__(self):\n",
    "                    self.alerts = []\n",
    "            alert_system = DummyAlertSystem()\n",
    "            \n",
    "        export_data(future_years, future_values, ALERT_THRESHOLD_OVERALL, alert_system, \n",
    "                    model_forecasts, model_thresholds, df_clean)\n",
    "    \n",
    "    # ===== AGGREGATOR & BROWSER =====\n",
    "    if ENABLE_AGGREGATOR:\n",
    "        create_aggregator_html()\n",
    "        zip_all_outputs()\n",
    "    \n",
    "    # ===== FINAL SUMMARY =====\n",
    "    if ENABLE_REPORTING and df_clean is not None:\n",
    "        average_sales = df_yearly['Total_Sales'].mean() if df_yearly is not None else 0\n",
    "        \n",
    "        # Create dummy data for summary if missing\n",
    "        if ts_data is None:\n",
    "            ts_data = np.array([0, 0])\n",
    "        if ts_years is None:\n",
    "            ts_years = np.array([2020, 2021])\n",
    "        if future_values is None:\n",
    "            future_values = np.array([0, 0, 0])\n",
    "        if future_years is None:\n",
    "            future_years = np.array([datetime.now().year + i for i in range(1, 4)])\n",
    "        if alert_system is None:\n",
    "            # Create a dummy object with an alerts attribute\n",
    "            class DummyAlertSystem:\n",
    "                def __init__(self):\n",
    "                    self.alerts = []\n",
    "            alert_system = DummyAlertSystem()\n",
    "\n",
    "        generate_final_summary(df_clean, average_sales, ts_years, ts_data, future_years, \n",
    "                            future_values, model_forecasts, alert_system)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUCCESS: All tasks completed successfully!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
